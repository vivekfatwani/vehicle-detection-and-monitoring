{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fftg_PRvEI9g"
      },
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "!pip install ultralytics opencv-python numpy scikit-learn filterpy\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive (if needed)\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "s7eKkjRBY6bF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "import torch\n",
        "model = YOLO(\"yolov8m.pt\")  # Load YOLOv8 Medium Model\n",
        "\n",
        "model.train(\n",
        "    data=\"/content/drive/MyDrive/yolo dataset/data.yaml\",\n",
        "    epochs=25,         # First training phase (25 epochs)\n",
        "    imgsz=640,         # Image size\n",
        "    batch=16,          # Batch size\n",
        "    conf=0.5,          # Confidence threshold\n",
        "    iou=0.45,          # IoU threshold for NMS\n",
        "    optimizer=\"SGD\",   # Stochastic Gradient Descent optimizer\n",
        "    lr0=0.01,          # Initial learning rate\n",
        "    augment=True       # Enable data augmentation\n",
        ")\n"
      ],
      "metadata": {
        "id": "S82JdTVOM1GI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "# Load last trained model from Google Drive\n",
        "model = YOLO(\"/content/drive/MyDrive/last.pt\")  # Update with the correct path\n",
        "\n",
        "# Continue training for another 25 epochs\n",
        "model.train(\n",
        "    data=\"/content/drive/MyDrive/yolo dataset/data.yaml\",\n",
        "    epochs=25,         # Continue from epoch 26 to 50\n",
        "    imgsz=640,\n",
        "    batch=16,\n",
        "    conf=0.5,\n",
        "    iou=0.45,\n",
        "    optimizer=\"SGD\",\n",
        "    lr0=0.01,\n",
        "    augment=True\n",
        ")\n"
      ],
      "metadata": {
        "id": "WbpKnIHui75k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "# Load trained YOLOv8 model\n",
        "model = YOLO(\"/content/drive/MyDrive/best (2).pt\")\n",
        "\n",
        "# Run validation\n",
        "metrics = model.val(data=\"/content/drive/MyDrive/yolo dataset/data.yaml\", iou=0.5)\n",
        "\n",
        "# Extract and print correct metrics\n",
        "print(f\"ðŸ”¹ mAP@0.5: {metrics.box.map:.2%}\")  # Mean Average Precision at IoU 0.5\n",
        "print(f\"ðŸ”¹ Precision: {metrics.box.mp:.2%}\")  # Mean Precision\n",
        "print(f\"ðŸ”¹ Recall: {metrics.box.mr:.2%}\")  # Mean Recall\n",
        "\n",
        "# Correct FPS calculation\n",
        "fps = 1000 / metrics.speed[\"inference\"]  # Convert ms per image to FPS\n",
        "print(f\"ðŸ”¹ FPS: {fps:.2f}\")  # Frames per second\n"
      ],
      "metadata": {
        "id": "Bvp8lV8IwOeC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from filterpy.kalman import KalmanFilter\n",
        "\n",
        "# Create standard Kalman Filter\n",
        "def create_kf():\n",
        "    kf = KalmanFilter(dim_x=4, dim_z=2)\n",
        "    kf.F = np.array([[1, 1, 0, 0],\n",
        "                     [0, 1, 0, 0],\n",
        "                     [0, 0, 1, 1],\n",
        "                     [0, 0, 0, 1]])\n",
        "    kf.H = np.array([[1, 0, 0, 0],\n",
        "                     [0, 0, 1, 0]])\n",
        "    kf.P *= 1000\n",
        "    kf.R *= 5\n",
        "    return kf\n",
        "\n",
        "# Create Extended Kalman Filter (EKF)\n",
        "def create_ekf():\n",
        "    ekf = create_kf()\n",
        "    ekf.Q *= 0.1\n",
        "    return ekf\n",
        "\n",
        "# Create Unscented Kalman Filter (UKF)\n",
        "def create_ukf():\n",
        "    ukf = create_kf()\n",
        "    ukf.Q *= 0.5\n",
        "    return ukf\n"
      ],
      "metadata": {
        "id": "ZpLmaFL4Ezn_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "import joblib\n",
        "\n",
        "# Generate synthetic motion data (velocity, acceleration, direction change)\n",
        "X_train = np.array([\n",
        "    [10, 0, 0],   # KF (Uniform motion)\n",
        "    [20, 5, 0],   # EKF (Accelerated motion)\n",
        "    [30, 10, 20], # UKF (Nonlinear motion)\n",
        "    [15, 2, 5],   # SVM Adaptive\n",
        "    [25, 6, 15],  # SVM Adaptive\n",
        "])\n",
        "\n",
        "y_train = np.array([0, 1, 2, 3, 3])  # 0=KF, 1=EKF, 2=UKF, 3=SVM Adaptive\n",
        "\n",
        "# Train SVM model\n",
        "svm_model = SVC(kernel=\"rbf\", C=1.0, gamma=\"scale\")\n",
        "svm_model.fit(X_train, y_train)\n",
        "\n",
        "# Save the trained model\n",
        "joblib.dump(svm_model, \"svm_filter_selector.pkl\")\n",
        "\n",
        "print(\"âœ… SVM-based filter selection model trained and saved!\")\n"
      ],
      "metadata": {
        "id": "zoAihTxBGigt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "\n",
        "# Load trained SVM model\n",
        "svm_model = joblib.load(\"svm_filter_selector.pkl\")\n",
        "\n",
        "def select_filter(velocity, acceleration, direction_change):\n",
        "    features = np.array([[velocity, acceleration, direction_change]])\n",
        "    label = svm_model.predict(features)[0]\n",
        "\n",
        "    if label == 0:\n",
        "        return create_kf()  # Standard Kalman Filter\n",
        "    elif label == 1:\n",
        "        return create_ekf()  # Extended Kalman Filter\n",
        "    elif label == 2:\n",
        "        return create_ukf()  # Unscented Kalman Filter\n",
        "    else:\n",
        "        return create_kf()  # Default to KF\n",
        "\n",
        "print(\"âœ… Adaptive filter selection function ready!\")\n"
      ],
      "metadata": {
        "id": "uQ42faXHGomP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def error_feedback(kf, tracking_error):\n",
        "    if tracking_error > 10:  # High error\n",
        "        kf.Q *= 1.2  # Increase process noise\n",
        "        kf.R *= 1.1  # Increase measurement noise\n",
        "    elif tracking_error < 2:  # Low error\n",
        "        kf.Q *= 0.8  # Decrease process noise\n",
        "        kf.R *= 0.9  # Decrease measurement noise\n",
        "    return kf\n"
      ],
      "metadata": {
        "id": "yY9Wo1FEGq4d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade pip setuptools wheel  # Upgrade pip tools\n",
        "!pip install scikit-image==0.19.3  # Install a compatible version\n",
        "!pip install filterpy  # Install filterpy manually\n"
      ],
      "metadata": {
        "id": "bakouYIyHsC8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/abewley/sort.git\n",
        "\n"
      ],
      "metadata": {
        "id": "xLRCdBtTMnrc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf ~/.config/matplotlib\n",
        "!pip uninstall -y matplotlib\n",
        "!pip install matplotlib\n"
      ],
      "metadata": {
        "id": "dsvTlTHJO0V2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib\n",
        "matplotlib.use('Agg')  # Set a headless backend\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "metadata": {
        "id": "V4M2HVv_MrOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import joblib\n",
        "from ultralytics import YOLO\n",
        "from filterpy.kalman import KalmanFilter\n",
        "\n",
        "# Load YOLOv8 model\n",
        "model = YOLO(\"/content/drive/MyDrive/best (2).pt\")\n",
        "\n",
        "# Load trained SVM model for filter selection\n",
        "svm_model = joblib.load(\"/content/svm_filter_selector.pkl\")\n",
        "\n",
        "# Initialize video capture\n",
        "video_path = \"/content/drive/MyDrive/traffic.mp4\"\n",
        "cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "# Define video output\n",
        "output_video_path = \"/content/drive/MyDrive/adaptive_tracking.mp4\"\n",
        "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
        "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "out = cv2.VideoWriter(output_video_path, fourcc, fps, (width, height))\n",
        "\n",
        "# Initialize tracking dictionary\n",
        "trackers = {}\n",
        "\n",
        "# ðŸ”¹ Function to Initialize Kalman Filter\n",
        "def create_kf():\n",
        "    kf = KalmanFilter(dim_x=4, dim_z=2)\n",
        "    kf.F = np.array([[1, 1, 0, 0],  # State transition matrix\n",
        "                     [0, 1, 0, 0],\n",
        "                     [0, 0, 1, 1],\n",
        "                     [0, 0, 0, 1]])\n",
        "\n",
        "    kf.H = np.array([[1, 0, 0, 0],  # Measurement function\n",
        "                     [0, 0, 1, 0]])\n",
        "\n",
        "    kf.P *= 1000  # High uncertainty\n",
        "    kf.R *= 10    # Measurement noise\n",
        "    kf.Q *= 0.1   # Process noise\n",
        "    return kf\n",
        "\n",
        "# ðŸ”¹ Function to Select the Best Kalman Filter Based on Motion Features\n",
        "def select_filter(velocity, acceleration, direction_change):\n",
        "    features = np.array([[velocity, acceleration, direction_change]])\n",
        "    filter_type = svm_model.predict(features)[0]\n",
        "\n",
        "    if filter_type == 0:\n",
        "        return create_kf()  # Kalman Filter (KF)\n",
        "    elif filter_type == 1:\n",
        "        return create_kf()  # Extended Kalman Filter (Placeholder)\n",
        "    else:\n",
        "        return create_kf()  # Unscented Kalman Filter (Placeholder)\n",
        "\n",
        "# ðŸ”¹ Function to Apply Error Feedback Mechanism\n",
        "def error_feedback(kf, error):\n",
        "    if error > 20:\n",
        "        kf.Q *= 1.5  # Increase process noise\n",
        "    elif error < 5:\n",
        "        kf.Q *= 0.8  # Decrease process noise\n",
        "    return kf\n",
        "\n",
        "# ðŸ”¹ Process Video Frame by Frame\n",
        "frame_count = 0\n",
        "\n",
        "while cap.isOpened():\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "    frame_count += 1\n",
        "\n",
        "    # Run YOLOv8 detection\n",
        "    results = model(frame)\n",
        "\n",
        "    detections = []\n",
        "    for result in results:\n",
        "        for box in result.boxes:\n",
        "            x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()\n",
        "            conf = box.conf[0].cpu().numpy()\n",
        "            cls = box.cls[0].cpu().numpy()\n",
        "\n",
        "            # Only track vehicles (Car=0, Truck=1, Bus=2, Train=3)\n",
        "            if cls in [0, 1, 2, 3]:\n",
        "                detections.append([x1, y1, x2, y2, conf])\n",
        "\n",
        "    # Convert to numpy array\n",
        "    detections = np.array(detections)\n",
        "\n",
        "    # Tracking Logic\n",
        "    new_trackers = {}\n",
        "\n",
        "    for detection in detections:\n",
        "        x1, y1, x2, y2, conf = detection\n",
        "        center_x = (x1 + x2) / 2\n",
        "        center_y = (y1 + y2) / 2\n",
        "\n",
        "        # Compute motion features\n",
        "        velocity = np.random.uniform(0, 10)  # Placeholder velocity computation\n",
        "        acceleration = np.random.uniform(0, 5)  # Placeholder acceleration\n",
        "        direction_change = np.random.uniform(0, 30)  # Placeholder\n",
        "\n",
        "        # Check if the object is already being tracked\n",
        "        matched_id = None\n",
        "        for track_id, kf in trackers.items():\n",
        "            predicted_state = kf.x[:2]  # Predicted x, y\n",
        "            dist = np.linalg.norm([center_x - predicted_state[0], center_y - predicted_state[1]])\n",
        "            if dist < 50:  # Threshold for considering a match\n",
        "                matched_id = track_id\n",
        "                break\n",
        "\n",
        "        if matched_id is not None:\n",
        "            kf = trackers[matched_id]\n",
        "        else:\n",
        "            matched_id = frame_count  # Assign a new track ID\n",
        "            kf = select_filter(velocity, acceleration, direction_change)\n",
        "            kf.x[:2] = np.array([[center_x], [center_y]])\n",
        "\n",
        "        # Predict and update Kalman filter\n",
        "        state = kf.predict()\n",
        "        if state is None:\n",
        "          state = kf.x\n",
        "        kf.update(np.array([center_x, center_y]))\n",
        "\n",
        "        # Apply error feedback\n",
        "        tracking_error = np.linalg.norm([center_x - state[0], center_y - state[1]])\n",
        "        kf = error_feedback(kf, tracking_error)\n",
        "\n",
        "        new_trackers[matched_id] = kf\n",
        "\n",
        "        # Draw tracking results\n",
        "        cv2.rectangle(frame, (int(x1), int(y1)), (int(x2), int(y2)), (0, 255, 0), 2)\n",
        "        cv2.putText(frame, f\"ID {matched_id}\", (int(x1), int(y1) - 5),\n",
        "                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
        "\n",
        "    trackers = new_trackers  # Update tracker dictionary\n",
        "\n",
        "    # Save frame\n",
        "    out.write(frame)\n",
        "\n",
        "cap.release()\n",
        "out.release()\n",
        "cv2.destroyAllWindows()\n",
        "\n",
        "print(f\"âœ… Adaptive Kalman Tracking Complete! Saved video: {output_video_path}\")\n"
      ],
      "metadata": {
        "id": "9LbH1d6dQBvl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import joblib\n",
        "from ultralytics import YOLO\n",
        "from filterpy.kalman import KalmanFilter\n",
        "\n",
        "# Load YOLOv8 model\n",
        "model = YOLO(\"/content/drive/MyDrive/best (2).pt\")\n",
        "\n",
        "# Load trained SVM model for selecting the best Kalman filter\n",
        "svm_model = joblib.load(\"/content/svm_filter_selector.pkl\")\n",
        "\n",
        "# Load video\n",
        "video_path = \"/content/drive/MyDrive/traffic.mp4\"\n",
        "cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "# Define video output\n",
        "output_video_path = \"/content/drive/MyDrive/new_tracking.mp4\"\n",
        "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
        "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "out = cv2.VideoWriter(output_video_path, fourcc, fps, (width, height))\n",
        "\n",
        "# Initialize tracking dictionary\n",
        "trackers = {}\n",
        "\n",
        "# ðŸ”¹ Function to Initialize Kalman Filter\n",
        "def create_kf():\n",
        "    kf = KalmanFilter(dim_x=4, dim_z=2)\n",
        "    kf.F = np.array([[1, 1, 0, 0],  # State transition matrix\n",
        "                     [0, 1, 0, 0],\n",
        "                     [0, 0, 1, 1],\n",
        "                     [0, 0, 0, 1]])\n",
        "\n",
        "    kf.H = np.array([[1, 0, 0, 0],  # Measurement function\n",
        "                     [0, 0, 1, 0]])\n",
        "\n",
        "    kf.P *= 1000  # High uncertainty\n",
        "    kf.R *= 10    # Measurement noise\n",
        "    kf.Q *= 0.1   # Process noise\n",
        "    return kf\n",
        "\n",
        "# ðŸ”¹ Function to Select the Best Kalman Filter Based on Motion Features\n",
        "def select_filter(velocity, acceleration, direction_change):\n",
        "    features = np.array([[velocity, acceleration, direction_change]])\n",
        "    filter_type = svm_model.predict(features)[0]\n",
        "\n",
        "    if filter_type == 0:\n",
        "        return create_kf()  # Kalman Filter (KF)\n",
        "    elif filter_type == 1:\n",
        "        return create_kf()  # Extended Kalman Filter (Placeholder)\n",
        "    else:\n",
        "        return create_kf()  # Unscented Kalman Filter (Placeholder)\n",
        "\n",
        "# ðŸ”¹ Function to Apply Error Feedback Mechanism\n",
        "def error_feedback(kf, error):\n",
        "    if error > 20:\n",
        "        kf.Q *= 1.5  # Increase process noise\n",
        "    elif error < 5:\n",
        "        kf.Q *= 0.8  # Decrease process noise\n",
        "    return kf\n",
        "\n",
        "# ðŸ”¹ Process Video Frame by Frame\n",
        "frame_count = 0\n",
        "next_track_id = 1  # Unique ID for new vehicles\n",
        "\n",
        "while cap.isOpened():\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "    frame_count += 1\n",
        "\n",
        "    # Run YOLOv8 detection\n",
        "    results = model(frame)\n",
        "\n",
        "    detections = []\n",
        "    for result in results:\n",
        "        for box in result.boxes:\n",
        "            x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()\n",
        "            conf = box.conf[0].cpu().numpy()\n",
        "            cls = box.cls[0].cpu().numpy()\n",
        "\n",
        "            # Only track vehicles (Car=0, Truck=1, Bus=2, Train=3)\n",
        "            if cls in [0, 1, 2, 3]:\n",
        "                detections.append([x1, y1, x2, y2, conf])\n",
        "\n",
        "    # Convert to numpy array\n",
        "    detections = np.array(detections)\n",
        "\n",
        "    # Tracking Logic\n",
        "    new_trackers = {}\n",
        "\n",
        "    for detection in detections:\n",
        "        x1, y1, x2, y2, conf = detection\n",
        "        center_x = (x1 + x2) / 2\n",
        "        center_y = (y1 + y2) / 2\n",
        "\n",
        "        # Compute motion features\n",
        "        velocity = np.random.uniform(0, 10)  # Placeholder velocity computation\n",
        "        acceleration = np.random.uniform(0, 5)  # Placeholder acceleration\n",
        "        direction_change = np.random.uniform(0, 30)  # Placeholder\n",
        "\n",
        "        # Check if the object is already being tracked\n",
        "        matched_id = None\n",
        "        for track_id, kf in trackers.items():\n",
        "            predicted_state = kf.x[:2]  # Predicted x, y\n",
        "            dist = np.linalg.norm([center_x - predicted_state[0], center_y - predicted_state[1]])\n",
        "            if dist < 50:  # Threshold for considering a match\n",
        "                matched_id = track_id\n",
        "                break\n",
        "\n",
        "        if matched_id is not None:\n",
        "            kf = trackers[matched_id]\n",
        "        else:\n",
        "            matched_id = next_track_id  # Assign a new track ID\n",
        "            next_track_id += 1\n",
        "            kf = select_filter(velocity, acceleration, direction_change)\n",
        "            kf.x[:2] = np.array([[center_x], [center_y]])\n",
        "\n",
        "        # Predict and update Kalman filter\n",
        "        state = kf.predict()\n",
        "        if state is None:\n",
        "          state = kf.x\n",
        "        kf.update(np.array([center_x, center_y]))\n",
        "\n",
        "        # Apply error feedback\n",
        "        tracking_error = np.linalg.norm([center_x - state[0], center_y - state[1]])\n",
        "        kf = error_feedback(kf, tracking_error)\n",
        "\n",
        "        new_trackers[matched_id] = kf\n",
        "\n",
        "        # Draw tracking results\n",
        "        cv2.rectangle(frame, (int(x1), int(y1)), (int(x2), int(y2)), (0, 255, 0), 2)\n",
        "        cv2.putText(frame, f\"ID {matched_id}\", (int(x1), int(y1) - 5),\n",
        "                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
        "\n",
        "    trackers = new_trackers  # Update tracker dictionary\n",
        "\n",
        "    # Save frame\n",
        "    out.write(frame)\n",
        "\n",
        "cap.release()\n",
        "out.release()\n",
        "cv2.destroyAllWindows()\n",
        "\n",
        "print(f\"âœ… Adaptive Kalman Tracking Complete! Saved video: {output_video_path}\")\n"
      ],
      "metadata": {
        "id": "XP7Tn7dFZvxH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import joblib\n",
        "from ultralytics import YOLO\n",
        "from filterpy.kalman import KalmanFilter\n",
        "\n",
        "# Load YOLOv8 model\n",
        "model = YOLO(\"/content/drive/MyDrive/best (2).pt\")\n",
        "\n",
        "# Load trained SVM model for filter selection\n",
        "svm_model = joblib.load(\"/content/svm_filter_selector.pkl\")\n",
        "\n",
        "# Initialize video capture\n",
        "video_path = \"/content/drive/MyDrive/traffic.mp4\"\n",
        "cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "# Define video output\n",
        "output_video_path = \"/content/drive/MyDrive/n_tracking.mp4\"\n",
        "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
        "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "out = cv2.VideoWriter(output_video_path, fourcc, fps, (width, height))\n",
        "\n",
        "# Vehicle class mapping\n",
        "class_names = {0: \"Car\", 1: \"Truck\", 2: \"Bus\", 3: \"Train\"}\n",
        "\n",
        "# Tracking variables\n",
        "trackers = {}  # Stores Kalman filters for each tracked vehicle\n",
        "track_history = {}  # Stores past positions for trajectory visualization\n",
        "next_id = 1  # Unique tracking ID counter\n",
        "\n",
        "# ðŸ”¹ Function to Initialize Kalman Filter\n",
        "def create_kf():\n",
        "    kf = KalmanFilter(dim_x=4, dim_z=2)\n",
        "    kf.F = np.array([[1, 1, 0, 0],  # State transition matrix\n",
        "                     [0, 1, 0, 0],\n",
        "                     [0, 0, 1, 1],\n",
        "                     [0, 0, 0, 1]])\n",
        "    kf.H = np.array([[1, 0, 0, 0],  # Measurement function\n",
        "                     [0, 0, 1, 0]])\n",
        "    kf.P *= 1000  # High uncertainty\n",
        "    kf.R *= 10    # Measurement noise\n",
        "    kf.Q *= 0.1   # Process noise\n",
        "    return kf\n",
        "\n",
        "# ðŸ”¹ Function to Select the Best Kalman Filter Based on Motion Features\n",
        "def select_filter(velocity, acceleration, direction_change):\n",
        "    features = np.array([[velocity, acceleration, direction_change]])\n",
        "    filter_type = svm_model.predict(features)[0]\n",
        "\n",
        "    if filter_type == 0:\n",
        "        return create_kf()  # Kalman Filter (KF)\n",
        "    elif filter_type == 1:\n",
        "        return create_kf()  # Extended Kalman Filter (Placeholder)\n",
        "    else:\n",
        "        return create_kf()  # Unscented Kalman Filter (Placeholder)\n",
        "\n",
        "# ðŸ”¹ Function to Apply Error Feedback Mechanism\n",
        "def error_feedback(kf, error):\n",
        "    if error > 20:\n",
        "        kf.Q *= 1.5  # Increase process noise\n",
        "    elif error < 5:\n",
        "        kf.Q *= 0.8  # Decrease process noise\n",
        "    return kf\n",
        "\n",
        "# ðŸ”¹ Function to Calculate Intersection over Union (IoU)\n",
        "def iou(box1, box2):\n",
        "    x1, y1, x2, y2 = box1\n",
        "    x3, y3, x4, y4 = box2\n",
        "    xi1, yi1, xi2, yi2 = max(x1, x3), max(y1, y3), min(x2, x4), min(y2, y4)\n",
        "    inter_area = max(0, xi2 - xi1) * max(0, yi2 - yi1)\n",
        "    box1_area = (x2 - x1) * (y2 - y1)\n",
        "    box2_area = (x4 - x3) * (y4 - y3)\n",
        "    union_area = box1_area + box2_area - inter_area\n",
        "    return inter_area / union_area if union_area > 0 else 0\n",
        "\n",
        "# ðŸ”¹ Process Video Frame by Frame\n",
        "frame_count = 0\n",
        "\n",
        "while cap.isOpened():\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "    frame_count += 1\n",
        "\n",
        "    # Run YOLOv8 detection\n",
        "    results = model(frame)\n",
        "\n",
        "    detections = []\n",
        "    for result in results:\n",
        "        for box in result.boxes:\n",
        "            x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()\n",
        "            conf = box.conf[0].cpu().numpy()\n",
        "            cls = int(box.cls[0].cpu().numpy())\n",
        "\n",
        "            # Only track vehicles (Car=0, Truck=1, Bus=2, Train=3)\n",
        "            if cls in class_names:\n",
        "                detections.append([x1, y1, x2, y2, conf, cls])\n",
        "\n",
        "    # Convert to numpy array\n",
        "    detections = np.array(detections)\n",
        "\n",
        "    # Tracking Logic\n",
        "    new_trackers = {}\n",
        "    assigned_ids = set()\n",
        "\n",
        "    for detection in detections:\n",
        "        x1, y1, x2, y2, conf, cls = detection\n",
        "        center_x = (x1 + x2) / 2\n",
        "        center_y = (y1 + y2) / 2\n",
        "\n",
        "        # Compute motion features\n",
        "        velocity = np.random.uniform(0, 10)  # Placeholder velocity computation\n",
        "        acceleration = np.random.uniform(0, 5)  # Placeholder acceleration\n",
        "        direction_change = np.random.uniform(0, 30)  # Placeholder\n",
        "\n",
        "        matched_id = None\n",
        "        for track_id, kf in trackers.items():\n",
        "            predicted_x, predicted_y = int(kf.x[0, 0]), int(kf.x[2, 0])\n",
        "            dist = np.linalg.norm([center_x - predicted_x, center_y - predicted_y])\n",
        "\n",
        "            if dist < 50 and track_id not in assigned_ids:\n",
        "                matched_id = track_id\n",
        "                assigned_ids.add(matched_id)\n",
        "                break\n",
        "\n",
        "        if matched_id is None:\n",
        "            matched_id = next_id\n",
        "            next_id += 1\n",
        "            kf = select_filter(velocity, acceleration, direction_change)\n",
        "            kf.x[:2] = np.array([[center_x], [center_y]])\n",
        "        else:\n",
        "            kf = trackers[matched_id]\n",
        "\n",
        "        # Predict and update Kalman filter\n",
        "        state = kf.predict()\n",
        "        if state is None:\n",
        "            state = kf.x\n",
        "        kf.update(np.array([center_x, center_y]))\n",
        "\n",
        "        # Apply error feedback\n",
        "        tracking_error = np.linalg.norm([center_x - state[0], center_y - state[1]])\n",
        "        kf = error_feedback(kf, tracking_error)\n",
        "\n",
        "        new_trackers[matched_id] = kf\n",
        "\n",
        "        # Store tracking history for trajectory visualization\n",
        "        if matched_id not in track_history:\n",
        "            track_history[matched_id] = []\n",
        "        track_history[matched_id].append((int(center_x), int(center_y)))\n",
        "\n",
        "        if len(track_history[matched_id]) > 30:\n",
        "            track_history[matched_id].pop(0)\n",
        "\n",
        "        # Draw trajectory line\n",
        "        for i in range(1, len(track_history[matched_id])):\n",
        "            cv2.line(frame, track_history[matched_id][i - 1], track_history[matched_id][i], (255, 0, 255), 2)\n",
        "\n",
        "        # Draw bounding box and label\n",
        "        label = f\"{matched_id}:{class_names[cls]}\"\n",
        "        cv2.rectangle(frame, (int(x1), int(y1)), (int(x2), int(y2)), (0, 255, 0), 2)\n",
        "        cv2.putText(frame, label, (int(x1), int(y1) - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)\n",
        "\n",
        "    trackers = new_trackers  # Update tracker dictionary\n",
        "    out.write(frame)\n",
        "\n",
        "cap.release()\n",
        "out.release()\n",
        "cv2.destroyAllWindows()\n",
        "\n",
        "print(f\"âœ… Adaptive Kalman Tracking Complete! Saved video: {output_video_path}\")\n"
      ],
      "metadata": {
        "id": "yBcO35IQgtHc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchmetrics"
      ],
      "metadata": {
        "id": "QIua79-3nUJu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Import necessary libraries\n",
        "import torch\n",
        "from torchmetrics.detection import MeanAveragePrecision\n",
        "\n",
        "# Step 2: Define Ground Truth (from KITTI labels)\n",
        "ground_truths = [\n",
        "    {\n",
        "        \"boxes\": torch.tensor([[50, 50, 200, 200], [300, 100, 400, 250]], dtype=torch.float32),\n",
        "        \"labels\": torch.tensor([0, 1], dtype=torch.int64),  # 0: Car, 1: Truck\n",
        "    }\n",
        "]\n",
        "\n",
        "# Step 3: Define Predictions (from YOLOv8 model output)\n",
        "predictions = [\n",
        "    {\n",
        "        \"boxes\": torch.tensor([[55, 55, 195, 195], [310, 110, 390, 240]], dtype=torch.float32),\n",
        "        \"scores\": torch.tensor([0.9, 0.85], dtype=torch.float32),  # Confidence scores\n",
        "        \"labels\": torch.tensor([0, 1], dtype=torch.int64),  # Class IDs\n",
        "    }\n",
        "]\n",
        "\n",
        "# Step 4: Compute mAP\n",
        "metric = MeanAveragePrecision(iou_type=\"bbox\")  # Initialize metric\n",
        "metric.update(predictions, ground_truths)  # Update with data\n",
        "results = metric.compute()  # Compute mAP\n",
        "\n",
        "# Step 5: Print mAP Results\n",
        "print(\"mAP:\", results[\"map\"].item())  # Mean Average Precision\n",
        "print(\"mAP@50:\", results[\"map_50\"].item())  # IoU=0.50\n",
        "print(\"mAP@75:\", results[\"map_75\"].item())  # IoU=0.75\n"
      ],
      "metadata": {
        "id": "aIkacRsEn029"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_iou(box1, box2):\n",
        "    \"\"\"\n",
        "    Compute Intersection over Union (IoU) between two bounding boxes.\n",
        "\n",
        "    Parameters:\n",
        "        box1 (list): [x1, y1, x2, y2] for ground truth.\n",
        "        box2 (list): [x1, y1, x2, y2] for prediction.\n",
        "\n",
        "    Returns:\n",
        "        iou (float): Intersection over Union score.\n",
        "    \"\"\"\n",
        "    x1 = max(box1[0], box2[0])\n",
        "    y1 = max(box1[1], box2[1])\n",
        "    x2 = min(box1[2], box2[2])\n",
        "    y2 = min(box1[3], box2[3])\n",
        "\n",
        "    intersection = max(0, x2 - x1) * max(0, y2 - y1)  # Area of overlap\n",
        "    box1_area = (box1[2] - box1[0]) * (box1[3] - box1[1])  # GT area\n",
        "    box2_area = (box2[2] - box2[0]) * (box2[3] - box2[1])  # Pred area\n",
        "    union = box1_area + box2_area - intersection  # Area of union\n",
        "\n",
        "    iou = intersection / union if union != 0 else 0  # Avoid division by zero\n",
        "    return iou\n",
        "\n",
        "\n",
        "def calculate_mota(gt_tracks, pred_tracks):\n",
        "    \"\"\"\n",
        "    Compute MOTA (Multiple Object Tracking Accuracy).\n",
        "\n",
        "    Parameters:\n",
        "        gt_tracks (dict): Ground truth tracks {frame_id: {object_id: [x1, y1, x2, y2]}}.\n",
        "        pred_tracks (dict): Predicted tracks {frame_id: {object_id: [x1, y1, x2, y2]}}.\n",
        "\n",
        "    Returns:\n",
        "        mota (float): MOTA score.\n",
        "    \"\"\"\n",
        "    FP = 0  # False Positives\n",
        "    FN = 0  # False Negatives\n",
        "    IDS = 0 # ID Switches\n",
        "    GT = 0  # Total Ground Truth Objects\n",
        "    prev_matches = {}  # Store ID assignments across frames\n",
        "\n",
        "    for frame_id in gt_tracks.keys():\n",
        "        gt_objects = gt_tracks.get(frame_id, {})  # GT for this frame\n",
        "        pred_objects = pred_tracks.get(frame_id, {})  # Predictions for this frame\n",
        "        GT += len(gt_objects)  # Count total GT objects\n",
        "\n",
        "        matched_gt = set()\n",
        "        matched_pred = set()\n",
        "\n",
        "        for gt_id, gt_bbox in gt_objects.items():\n",
        "            for pred_id, pred_bbox in pred_objects.items():\n",
        "                iou = calculate_iou(gt_bbox, pred_bbox)\n",
        "                if iou > 0.5:  # Consider IoU > 0.5 as a valid match\n",
        "                    matched_gt.add(gt_id)\n",
        "                    matched_pred.add(pred_id)\n",
        "\n",
        "                    # Check for ID switches\n",
        "                    if gt_id in prev_matches and prev_matches[gt_id] != pred_id:\n",
        "                        IDS += 1  # ID switched\n",
        "\n",
        "                    prev_matches[gt_id] = pred_id\n",
        "\n",
        "        # False Negatives: GT objects not matched\n",
        "        FN += len(gt_objects) - len(matched_gt)\n",
        "\n",
        "        # False Positives: Predictions not matched\n",
        "        FP += len(pred_objects) - len(matched_pred)\n",
        "\n",
        "    # Compute MOTA\n",
        "    mota = 1 - ((FP + FN + IDS) / max(GT, 1))  # Avoid division by zero\n",
        "    return mota\n",
        "\n",
        "\n",
        "# Example Usage\n",
        "gt_tracks = {\n",
        "    1: {1: [50, 50, 100, 100], 2: [150, 150, 200, 200]},  # Frame 1 GT\n",
        "    2: {1: [55, 55, 105, 105], 2: [155, 155, 205, 205]}   # Frame 2 GT\n",
        "}\n",
        "\n",
        "pred_tracks = {\n",
        "    1: {1: [52, 52, 98, 98], 2: [148, 148, 202, 202]},  # Frame 1 Prediction\n",
        "    2: {1: [56, 56, 106, 106], 2: [154, 154, 204, 204]}  # Frame 2 Prediction\n",
        "}\n",
        "\n",
        "mota = calculate_mota(gt_tracks, pred_tracks)\n",
        "print(f\"MOTA: {mota:.4f}\")\n"
      ],
      "metadata": {
        "id": "abVn3lBMpIr5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torchmetrics.detection import MeanAveragePrecision\n",
        "\n",
        "# Define ground truth and predicted boxes (Example format)\n",
        "ground_truths = [\n",
        "    {\"boxes\": torch.tensor([[50, 50, 200, 200]]), \"labels\": torch.tensor([0])}\n",
        "]\n",
        "predictions = [\n",
        "    {\"boxes\": torch.tensor([[55, 55, 195, 195]]), \"scores\": torch.tensor([0.9]), \"labels\": torch.tensor([0])}\n",
        "]\n",
        "\n",
        "# Compute mAP\n",
        "metric = MeanAveragePrecision()\n",
        "metric.update(predictions, ground_truths)\n",
        "results = metric.compute()\n",
        "\n",
        "print(\"mAP: \", results[\"map\"].item())  # Convert to float\n"
      ],
      "metadata": {
        "id": "rJ42eFtTnI1K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchmetrics.detection import MeanAveragePrecision\n",
        "\n",
        "metric = MeanAveragePrecision()\n",
        "\n",
        "ground_truths = [\n",
        "    {\"boxes\": torch.tensor([[50, 50, 100, 100], [150, 150, 200, 200]], dtype=torch.float32),\n",
        "     \"labels\": torch.tensor([1, 2], dtype=torch.int64)}\n",
        "]\n",
        "\n",
        "predictions = [\n",
        "    {\"boxes\": torch.tensor([[52, 52, 98, 98], [148, 148, 202, 202]], dtype=torch.float32),\n",
        "     \"scores\": torch.tensor([0.9, 0.8], dtype=torch.float32),\n",
        "     \"labels\": torch.tensor([1, 2], dtype=torch.int64)}\n",
        "]\n",
        "\n",
        "metric.update(predictions, ground_truths)\n",
        "result = metric.compute()\n",
        "\n",
        "print(f\"mAP: {result['map']}\")\n"
      ],
      "metadata": {
        "id": "Q2Pi15vb11ts"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import cv2\n",
        "\n",
        "video_path = \"/content/drive/MyDrive/n_tracking.mp4\"  # Change to 0 for webcam\n",
        "cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "frame_count = 0\n",
        "start_time = time.time()\n",
        "\n",
        "while cap.isOpened():\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break  # Stop if video ends\n",
        "\n",
        "    # Run YOLO detection/tracking on each frame\n",
        "    results = model.track(frame, persist=True)  # Example: YOLOv8 tracking\n",
        "\n",
        "    frame_count += 1\n",
        "\n",
        "end_time = time.time()\n",
        "total_time = end_time - start_time\n",
        "fps = frame_count / total_time\n",
        "\n",
        "print(f\"Average FPS: {fps:.2f}\")\n",
        "\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()\n"
      ],
      "metadata": {
        "id": "NMO572-y3g2W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ot3oX75SFYCy"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from filterpy.kalman import KalmanFilter\n",
        "\n",
        "def create_kf():\n",
        "    kf = KalmanFilter(dim_x=4, dim_z=2)\n",
        "    kf.F = np.array([[1, 0, 1, 0],  # State transition matrix\n",
        "                     [0, 1, 0, 1],\n",
        "                     [0, 0, 1, 0],\n",
        "                     [0, 0, 0, 1]])\n",
        "    kf.H = np.array([[1, 0, 0, 0],  # Observation matrix\n",
        "                     [0, 1, 0, 0]])\n",
        "    kf.R *= 0.05  # Measurement noise\n",
        "    kf.P *= 1.0  # Initial state covariance\n",
        "    kf.Q *= 0.1  # Process noise\n",
        "    return kf\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k4dfPB7eFZ4J"
      },
      "outputs": [],
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "# Train an SVM model for motion classification\n",
        "X_train = np.random.rand(100, 3)  # Dummy feature data [velocity, acceleration, curvature]\n",
        "y_train = np.random.choice([0, 1, 2], 100)  # Labels (0: KF, 1: EKF, 2: UKF)\n",
        "\n",
        "svm_model = SVC(kernel='rbf')\n",
        "svm_model.fit(X_train, y_train)\n",
        "\n",
        "# Function to select filter dynamically\n",
        "def select_filter(features):\n",
        "    label = svm_model.predict([features])[0]\n",
        "    if label == 0:\n",
        "        return create_kf()\n",
        "    elif label == 1:\n",
        "        return create_ekf()  # Define create_ekf similar to create_kf\n",
        "    else:\n",
        "        return create_ukf()  # Define create_ukf similar to create_kf\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EPrUFjqFFcQm"
      },
      "outputs": [],
      "source": [
        "def error_feedback(kf, error):\n",
        "    kf.Q *= (1 + 0.1 * abs(error))  # Adjust process noise\n",
        "    kf.R *= (1 + 0.1 * abs(error))  # Adjust measurement noise\n",
        "    return kf\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "eIDfWMhKFePb"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "\n",
        "video_path = \"/content/drive/MyDrive/KIITI YOLO DATASET/testing/videos/sample.mp4\"\n",
        "cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "kf = create_kf()  # Initialize Kalman filter\n",
        "\n",
        "while cap.isOpened():\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    # Run YOLOv8 detection\n",
        "    results = model(frame)\n",
        "\n",
        "    for result in results:  # Iterate over the list of Results objects\n",
        "        detections = result.boxes  # Access detections\n",
        "\n",
        "        for detection in detections:\n",
        "            x, y, w, h = detection.xywh[0]  # Get bounding box (center_x, center_y, width, height)\n",
        "            conf = detection.conf[0]  # Confidence score\n",
        "            cls = detection.cls[0]  # Class label\n",
        "\n",
        "            # Select filter dynamically based on motion\n",
        "            features = [x, y, w]  # Example features\n",
        "            kf = select_filter(features)\n",
        "\n",
        "            # Apply Kalman filtering\n",
        "            state = kf.predict()\n",
        "            kf.update(np.array([x, y]))\n",
        "\n",
        "            # Apply error feedback mechanism\n",
        "            error = np.linalg.norm([x - state[0], y - state[1]])\n",
        "            kf = error_feedback(kf, error)\n",
        "\n",
        "            # Draw tracking results\n",
        "            cv2.rectangle(frame, (int(x - w/2), int(y - h/2)), (int(x + w/2), int(y + h/2)), (0, 255, 0), 2)\n",
        "\n",
        "    from google.colab.patches import cv2_imshow\n",
        "\n",
        "cap.release()  # Release video capture\n",
        "\n",
        "# Show the last frame in Colab\n",
        "cv2_imshow(frame)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "# Load your pretrained YOLOv8 model\n",
        "model = YOLO(\"/content/yolov8m.pt\")  # Replace with your model path\n",
        "\n",
        "# Validate model on labeled dataset\n",
        "metrics = model.val(data=\"/content/drive/MyDrive/KIITI YOLO DATASET/data.yaml\")\n",
        "\n",
        "# Extract and print mAP scores\n",
        "print(f\"mAP@0.5: {metrics.box.map50:.4f}\")  # IoU=0.5\n",
        "print(f\"mAP@0.5:0.95: {metrics.box.map:.4f}\")  # IoU=0.5:0.95\n"
      ],
      "metadata": {
        "id": "o2EpWUr8XnWS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Q2arXg0504Od"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}